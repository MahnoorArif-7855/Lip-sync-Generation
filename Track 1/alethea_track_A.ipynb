{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9eqfpIxKp6I"
      },
      "source": [
        "# Track A — Single Image → Lip‑Synced Video\n",
        "\n",
        "This Colab notebook generates a **30–45s MP4** from a **single image + TTS audio** using **Wav2Lip** and **Coqui‑TTS**.\n",
        "\n",
        "**Pipeline**: Coqui TTS → `speech.wav` → Wav2Lip (with your image) → `final.mp4`"
      ],
      "id": "X9eqfpIxKp6I"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf8DzaeKKp6O",
        "outputId": "5f9ff09e-1ab2-404b-ffc3-04ad4cf7a4bf"
      },
      "source": [
        "# Cell 1 — System & deps\n",
        "!nvidia-smi || true\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip -q install opencv-python moviepy pydub soundfile librosa ffmpeg-python gdown # Removed version constraint\n",
        "!apt -q update && apt -q install -y ffmpeg\n",
        "!pip install --upgrade pip\n",
        "!pip install numpy==1.26.4 # Install a compatible version of numpy\n",
        "!pip install --upgrade TTS\n",
        "!pip install -q face-alignment==1.3.5\n",
        "!pip install librosa==0.10.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gruut 2.2.3 requires numpy<2.0.0,>=1.19.0, but you have numpy 2.0.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 25.6.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "nx-cugraph-cu12 25.6.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "id": "Zf8DzaeKKp6O"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Clean out conflicting installs\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "# 2) Reinstall all three from the SAME CUDA build (cu118 works well on Colab)\n",
        "!pip install --force-reinstall --index-url https://download.pytorch.org/whl/cu118 \\\n",
        "  torch torchvision torchaudio\n",
        "\n",
        "# 3) (Re)install Coqui-TTS without bumping torch/torchaudio\n",
        "!pip install numpy==1.26.4 # Install a compatible version of numpy\n",
        "!pip install --no-deps --upgrade TTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zzSLFPhOc263",
        "outputId": "87198a53-75db-44d4-b6fc-bf14c86f6a01"
      },
      "id": "zzSLFPhOc263",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu118\n",
            "Uninstalling torch-2.6.0+cu118:\n",
            "  Successfully uninstalled torch-2.6.0+cu118\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.3.1 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting setuptools>=40.8.0 (from triton==3.3.1->torch)\n",
            "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (905.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m140.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision, torchaudio\n",
            "\u001b[2K  Attempting uninstall: mpmath\n",
            "\u001b[2K    Found existing installation: mpmath 1.3.0\n",
            "\u001b[2K    Uninstalling mpmath-1.3.0:\n",
            "\u001b[2K      Successfully uninstalled mpmath-1.3.0\n",
            "\u001b[2K  Attempting uninstall: typing-extensions\n",
            "\u001b[2K    Found existing installation: typing_extensions 4.14.1\n",
            "\u001b[2K    Uninstalling typing_extensions-4.14.1:\n",
            "\u001b[2K      Successfully uninstalled typing_extensions-4.14.1\n",
            "\u001b[2K  Attempting uninstall: sympy\n",
            "\u001b[2K    Found existing installation: sympy 1.13.1\n",
            "\u001b[2K    Uninstalling sympy-1.13.1:\n",
            "\u001b[2K      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[2K  Attempting uninstall: setuptools\n",
            "\u001b[2K    Found existing installation: setuptools 75.2.0\n",
            "\u001b[2K    Uninstalling setuptools-75.2.0:\n",
            "\u001b[2K      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[2K  Attempting uninstall: pillow\n",
            "\u001b[2K    Found existing installation: pillow 11.3.0\n",
            "\u001b[2K    Uninstalling pillow-11.3.0:\n",
            "\u001b[2K      Successfully uninstalled pillow-11.3.0\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu11 11.8.86\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu11-11.8.86:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu11-11.8.86\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu11 2.21.5\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu11-2.21.5:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu11-2.21.5\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu11 11.7.5.86\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu11-11.7.5.86:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu11-11.7.5.86\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu11 10.3.0.86\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu11-10.3.0.86:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu11-10.3.0.86\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu11 10.9.0.58\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu11-10.9.0.58:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu11-10.9.0.58\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu11 11.8.89\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu11-11.8.89:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu11-11.8.89\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu11 11.8.89\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu11-11.8.89:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.8.89\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu11 11.8.87\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu11-11.8.87:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu11-11.8.87\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu11 11.11.3.6\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu11-11.11.3.6:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu11-11.11.3.6\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 1.26.4\n",
            "\u001b[2K    Uninstalling numpy-1.26.4:\n",
            "\u001b[2K      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[2K  Attempting uninstall: networkx\n",
            "\u001b[2K    Found existing installation: networkx 2.8.8\n",
            "\u001b[2K    Uninstalling networkx-2.8.8:\n",
            "\u001b[2K      Successfully uninstalled networkx-2.8.8\n",
            "\u001b[2K  Attempting uninstall: MarkupSafe\n",
            "\u001b[2K    Found existing installation: MarkupSafe 3.0.2\n",
            "\u001b[2K    Uninstalling MarkupSafe-3.0.2:\n",
            "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2\n",
            "\u001b[2K  Attempting uninstall: fsspec\n",
            "\u001b[2K    Found existing installation: fsspec 2025.3.0\n",
            "\u001b[2K    Uninstalling fsspec-2025.3.0:\n",
            "\u001b[2K      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[2K  Attempting uninstall: filelock\n",
            "\u001b[2K    Found existing installation: filelock 3.18.0\n",
            "\u001b[2K    Uninstalling filelock-3.18.0:\n",
            "\u001b[2K      Successfully uninstalled filelock-3.18.0\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.2.0\n",
            "\u001b[2K    Uninstalling triton-3.2.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.2.0\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu11 11.4.1.48\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu11-11.4.1.48:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu11-11.4.1.48\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu11\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu11 9.1.0.70\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu11-9.1.0.70:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu11-9.1.0.70\n",
            "\u001b[2K  Attempting uninstall: jinja2\n",
            "\u001b[2K    Found existing installation: Jinja2 3.1.6\n",
            "\u001b[2K    Uninstalling Jinja2-3.1.6:\n",
            "\u001b[2K      Successfully uninstalled Jinja2-3.1.6\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you have networkx 3.3 which is incompatible.\n",
            "gruut 2.2.3 requires numpy<2.0.0,>=1.19.0, but you have numpy 2.1.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.0.0 setuptools-70.2.0 sympy-1.13.3 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "fsspec",
                  "numpy",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "a4e9837abdf34dd08501e85efb664b55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.2\n",
            "    Uninstalling numpy-2.1.2:\n",
            "      Successfully uninstalled numpy-2.1.2\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoHFeErlKp6Q"
      },
      "source": [
        "\n",
        "\n",
        "If your **weights** (`wav2lip_gan.pth`) or **image** are in Drive, mount it here."
      ],
      "id": "WoHFeErlKp6Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4vWteqqKp6S",
        "outputId": "55b44a23-c2b6-4d98-96b3-88f78b6022b0"
      },
      "source": [
        "# Cell 3 — Get Wav2Lip repo\n",
        "%cd /content\n",
        "!git clone https://github.com/Rudrabha/Wav2Lip.git\n",
        "%cd /content/Wav2Lip\n",
        "!pip -q install -r requirements.txt\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Wav2Lip' already exists and is not an empty directory.\n",
            "/content/Wav2Lip\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84, 4.11.0.86, 4.12.0.88)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n"
          ]
        }
      ],
      "id": "j4vWteqqKp6S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYVq-BNQKp6S"
      },
      "source": [
        "## Weights: wav2lip_gan.pth\n",
        "- Manually upload (left pane → *files* → upload), then set the path."
      ],
      "id": "uYVq-BNQKp6S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pd8H7TeKp6U"
      },
      "source": [
        "# Cell 4C — (Optional) If you uploaded weights manually, set path and copy\n",
        "uploaded_weights = \"/content/wav2lip_gan.pth\"  # change if you uploaded with a different name\n",
        "if os.path.exists(uploaded_weights):\n",
        "    shutil.copy(uploaded_weights, \"/content/Wav2Lip/wav2lip_gan.pth\")\n",
        "    print(\"Copied uploaded weights to repo.\")\n",
        "else:\n",
        "    print(\"No manually uploaded weights detected at:\", uploaded_weights)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1pd8H7TeKp6U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XjZ8wKzKp6V"
      },
      "source": [
        "## Input Image\n",
        "Provide your image path. You can upload directly or use Drive. The code below shows both."
      ],
      "id": "6XjZ8wKzKp6V"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JlYwvEOKp6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11ca225-ea53-432f-afdd-4d5b440f2f1e"
      },
      "source": [
        "# Cell 5 — Set image path\n",
        "INPUT_IMAGE = \"/content/image_1.jpg\"  # change if you uploaded with another name\n",
        "# Example test image (optional):\n",
        "!wget -O /content/image_1.jpg https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg\n",
        "print(\"Using image:\", INPUT_IMAGE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-11 23:09:08--  https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 91814 (90K) [image/jpeg]\n",
            "Saving to: ‘/content/image_1.jpg’\n",
            "\n",
            "\r/content/image_1.jp   0%[                    ]       0  --.-KB/s               \r/content/image_1.jp 100%[===================>]  89.66K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-11 23:09:08 (3.60 MB/s) - ‘/content/image_1.jpg’ saved [91814/91814]\n",
            "\n",
            "Using image: /content/image_1.jpg\n"
          ]
        }
      ],
      "id": "0JlYwvEOKp6V"
    },
    {
      "cell_type": "code",
      "source": [
        "from TTS.api import TTS\n",
        "import torch\n",
        "\n",
        "\n",
        "tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\", progress_bar=False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tts.to(device)  # <-- replaces gpu=True\n",
        "TEXT = \"Hello! This is a demo for my Alethea AI assignment. I generated this audio and synced the lip movements to an image.\"\n",
        "OUT_WAV = \"/content/speech.wav\"\n",
        "tts.tts_to_file(text=TEXT, file_path=OUT_WAV)\n",
        "\n",
        "print(\"Saved:\", OUT_WAV)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V43i6MfvcRRi",
        "outputId": "7ec06d59-99c3-45a2-961c-60460c991217"
      },
      "id": "V43i6MfvcRRi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
            " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
            " > Using model: Tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Model's reduction rate `r` is set to: 1\n",
            " > Vocoder Model: hifigan\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Generator Model: hifigan_generator\n",
            " > Discriminator Model: hifigan_discriminator\n",
            "Removing weight norm...\n",
            " > Text splitted to sentences.\n",
            "['Hello!', 'This is a demo for my Alethea AI assignment.', 'I generated this audio and synced the lip movements to an image.']\n",
            " > Processing time: 9.441238403320312\n",
            " > Real-time factor: 0.9760113025711354\n",
            "Saved: /content/speech.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQa8DJ1Kp6Y"
      },
      "source": [
        "### Make the audio ~30–45s (optional)\n",
        "If your text is short, concatenate and trim to a target length."
      ],
      "id": "cIQa8DJ1Kp6Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMHF9QZKp6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846e1ccf-d18d-49de-eb9d-61ff434e2ab8"
      },
      "source": [
        "# Cell 7 — Pad/trim to ~35s\n",
        "import subprocess\n",
        "target_sec = 35\n",
        "with open(\"/content/concat.txt\", \"w\") as f:\n",
        "    for _ in range(3):\n",
        "        f.write(\"file '/content/speech.wav'\\n\")\n",
        "subprocess.run([\"ffmpeg\",\"-y\",\"-f\",\"concat\",\"-safe\",\"0\",\"-i\",\"/content/concat.txt\",\"-c\",\"copy\",\"/content/speech_long.wav\"], check=True)\n",
        "subprocess.run([\"ffmpeg\",\"-y\",\"-i\",\"/content/speech_long.wav\",\"-t\",str(target_sec),\"-acodec\",\"copy\",\"/content/speech.wav\"], check=True)\n",
        "print(\"Prepared /content/speech.wav (~35s)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared /content/speech.wav (~35s)\n"
          ]
        }
      ],
      "id": "rFMHF9QZKp6Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "audio_file = \"/content/Wav2Lip/audio.py\"\n",
        "\n",
        "with open(audio_file, \"r\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "patched_code = re.sub(\n",
        "    r\"librosa\\.filters\\.mel\\(\\s*hp\\.sample_rate\\s*,\\s*hp\\.n_fft\\s*,\",\n",
        "    \"librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft,\",\n",
        "    code,\n",
        "    count=1\n",
        ")\n",
        "\n",
        "if code != patched_code:\n",
        "    with open(audio_file, \"w\") as f:\n",
        "        f.write(patched_code)\n",
        "    print(\"✅ Patched librosa.filters.mel() call to use keyword arguments.\")\n",
        "else:\n",
        "    print(\"ℹ️ Patch not applied (line already updated or pattern not found).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iGR6MBMgvzX",
        "outputId": "fbedfe58-165d-4514-dc06-187130e4e389"
      },
      "id": "0iGR6MBMgvzX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched librosa.filters.mel() call to use keyword arguments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, io\n",
        "\n",
        "path = \"/content/Wav2Lip/inference.py\"\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "# Replace the torch.load(...) call inside _load(...) to include weights_only=False\n",
        "patched = re.sub(\n",
        "    r\"torch\\.load\\((\\s*checkpoint_path\\s*,)\",\n",
        "    r\"torch.load(\\1 weights_only=False,\",\n",
        "    code,\n",
        "    count=1\n",
        ")\n",
        "\n",
        "if code != patched:\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(patched)\n",
        "    print(\"✅ Patched inference.py to use weights_only=False\")\n",
        "else:\n",
        "    print(\"ℹ️ Patch not applied (pattern not found or already patched)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo-MGZ8ZiILB",
        "outputId": "5babc517-e805-4112-e802-48f0d6fd8b8a"
      },
      "id": "zo-MGZ8ZiILB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Patched inference.py to use weights_only=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \\\n",
        "  \"https://huggingface.co/Nekochu/Wav2Lip/resolve/main/wav2lip_gan.pth\" \\\n",
        "  -o /content/wav2lip_gan.pth\n",
        "print(\"Downloaded wav2lip_gan.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxcMBCyTi1V2",
        "outputId": "3315d65b-3aa3-4474-adb3-cbcff731aeb4"
      },
      "id": "ZxcMBCyTi1V2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1317  100  1317    0     0   4413      0 --:--:-- --:--:-- --:--:--  4419\n",
            "100  415M  100  415M    0     0  45.2M      0  0:00:09  0:00:09 --:--:-- 47.6M\n",
            "Downloaded wav2lip_gan.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run from repo root\n",
        "%cd /content/Wav2Lip\n",
        "\n",
        "# Ensure required folders exist\n",
        "!mkdir -p temp results\n",
        "\n",
        "# Run inference (single image)\n",
        "!python inference.py \\\n",
        "  --checkpoint_path /content/wav2lip_gan.pth \\\n",
        "  --face /content/image_1.jpg \\\n",
        "  --audio /content/speech.wav \\\n",
        "  --outfile results/final.mp4 \\\n",
        "  --static True \\\n",
        "  --resize_factor 2 \\\n",
        "  --pads 0 10 0 0 \\\n",
        "  --nosmooth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtFXDnzZj_So",
        "outputId": "cc9814ba-ca72-41ee-f159-563ee54efb70"
      },
      "id": "PtFXDnzZj_So",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Wav2Lip\n",
            "Using cpu for inference.\n",
            "Number of frames available for inference: 1\n",
            "(80, 2322)\n",
            "Length of mel chunks: 722\n",
            "  0% 0/6 [00:00<?, ?it/s]\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:02<00:00,  2.98s/it]\n",
            "Load checkpoint from: /content/wav2lip_gan.pth\n",
            "Model loaded\n",
            "100% 6/6 [02:41<00:00, 26.86s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '/content/speech.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:29.02, bitrate: 352 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:28.88, start: 0.000000, bitrate: 806 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 801 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mprofile High, level 3.0, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/final.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 512x512 [SAR 1:1 DAR 1:1], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 22050 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=  722 fps=112 q=-1.0 Lsize=     534kB time=00:00:28.97 bitrate= 151.0kbits/s speed= 4.5x    \n",
            "video:278kB audio:236kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.755175%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mframe I:3     Avg QP:16.76  size: 45502\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mframe P:225   Avg QP:18.49  size:   490\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mframe B:494   Avg QP:25.56  size:    76\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mconsecutive B-frames:  6.1%  6.1%  5.8% 82.0%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mmb I  I16..4:  2.8% 95.6%  1.7%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mmb P  I16..4:  0.0%  0.3%  0.0%  P16..4:  4.9%  1.2%  0.8%  0.0%  0.0%    skip:92.7%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  2.1%  0.1%  0.0%  direct: 0.0%  skip:97.7%  L0:46.5% L1:50.0% BI: 3.5%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0m8x8 transform intra:94.6% inter:91.3%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mcoded y,uvDC,uvAC intra: 91.3% 94.8% 65.5% inter: 0.9% 1.3% 0.1%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mi16 v,h,dc,p: 32% 21% 19% 28%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 11% 24%  6%  4%  6%  3%  9%  6%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 11%  9% 11% 10% 14%  5% 17%  7%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mi8c dc,h,v,p: 39% 14% 36% 12%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mref P L0: 63.8% 11.0% 15.1% 10.1%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mref B L0: 84.5% 11.0%  4.5%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mref B L1: 94.0%  6.0%\n",
            "\u001b[1;36m[libx264 @ 0x5b1ae36b1f00] \u001b[0mkb/s:78.81\n",
            "\u001b[1;36m[aac @ 0x5b1ae36b3e80] \u001b[0mQavg: 10002.067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "print(\"Exists?\", os.path.isfile(\"/content/Wav2Lip/results/final.mp4\"))\n",
        "shutil.copy(\"/content/Wav2Lip/results/final.mp4\", \"/content/final.mp4\")\n",
        "print(\"Saved -> /content/final.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM0q_CbBkEN_",
        "outputId": "bca97f02-80e5-4c21-c157-5d7e9d637850"
      },
      "id": "dM0q_CbBkEN_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n",
            "Saved -> /content/final.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRUcrDbnKp6a"
      },
      "source": [
        "---\n",
        "### Notes / Known Issues\n",
        "- TTS voice is basic; you can switch to another Coqui model name.\n",
        "- Keep your input image frontal with decent lighting for best results.\n",
        "- If you see CUDA OOM, reduce resolution or try a shorter audio.\n"
      ],
      "id": "oRUcrDbnKp6a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}