{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3B1p-rpZHmus",
      "metadata": {
        "id": "3B1p-rpZHmus"
      },
      "source": [
        "# Alethea AI – Track C (Problem C) · Colab Notebook\n",
        "\n",
        "This notebook builds a **config-driven video generation pipeline**:\n",
        "\n",
        "**Text → Segments → TTS → Loudness Normalization → Wav2Lip (per segment) → Validate/Conform → XFade Stitch**\n",
        "\n",
        "> Works end-to-end with a single face image. You can swap TTS/Wav2Lip models, change FPS/size/xfade in `CFG`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "CBIuBMOEHmvQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBIuBMOEHmvQ",
        "outputId": "907979be-b953-4a06-abd1-7c7b5ef3decd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Aug 13 13:14:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Platform: Linux-6.1.123+-x86_64-with-glibc2.35\n"
          ]
        }
      ],
      "source": [
        "#@title 0) Runtime check (GPU recommended)\n",
        "!nvidia-smi || true\n",
        "import sys, platform, os, subprocess, json, time, pathlib, textwrap, math, shutil, uuid\n",
        "from pathlib import Path\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "tzmAIj4UHmva",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzmAIj4UHmva",
        "outputId": "4de51058-1589-4e9e-ef30-dc28af2187b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut-ipa' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut-ipa'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut_lang_de' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut_lang_de'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut_lang_en' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut_lang_en'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut_lang_es' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut_lang_es'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'gruut_lang_fr' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'gruut_lang_fr'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'encodec' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'encodec'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Building 'bnnumerizer' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'bnnumerizer'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "nx-cugraph-cu12 25.6.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/content/Wav2Lip\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1RpC3p0B8wAAGo2m9qgZ1s2F4QWLWf2Pz\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1G8wQ4o3mI0b6p_5nD1i3m8v3qIvGk5ZU\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "/content\n",
            "Setup complete.\n"
          ]
        }
      ],
      "source": [
        "#@title 1) Install dependencies\n",
        "# FFMPEG + Python deps + Wav2Lip repo + Coqui TTS\n",
        "!apt-get -y update -qq\n",
        "!apt-get -y install -qq ffmpeg git\n",
        "!pip -q install --upgrade pip\n",
        "!pip -q install numpy==2.* soundfile librosa pyyaml tqdm moviepy==1.0.3\n",
        "!pip -q install TTS==0.22.0\n",
        "!pip -q install gdown\n",
        "# Clone Wav2Lip\n",
        "if not Path(\"Wav2Lip\").exists():\n",
        "  !git clone -q https://github.com/Rudrabha/Wav2Lip.git\n",
        "# Download pretrained weights (try GAN first, fallback to non-GAN)\n",
        "%cd /content/Wav2Lip\n",
        "!gdown -q --id 1RpC3p0B8wAAGo2m9qgZ1s2F4QWLWf2Pz -O wav2lip_gan.pth || true\n",
        "!gdown -q --id 1G8wQ4o3mI0b6p_5nD1i3m8v3qIvGk5ZU -O wav2lip.pth || true\n",
        "%cd /content\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cvE1ccZHNs8p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvE1ccZHNs8p",
        "outputId": "63139431-cf62-4c0b-cf44-c17384ec91bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~etworkx (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~etworkx (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~etworkx (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution ~etworkx (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~etworkx (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install opencv-python-headless==4.8.1.78 face-alignment==1.3.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "iBf0uNNdWuU4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBf0uNNdWuU4",
        "outputId": "836fade1-ce82-4bf5-b153-472df82647ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.22.0 requires pandas<2.0,>=1.4, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "arviz 0.22.0 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires pandas>=2.2, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mNumPy 1.26.4 | OpenCV 4.10.0 | pandas 1.5.3 | CUDA? True\n"
          ]
        }
      ],
      "source": [
        "# Core wheels that play nice together (NumPy 2 + OpenCV + Colab)\n",
        "!pip -q install \"numpy==1.26.4\" \"scipy>=1.13.0\" \"opencv-python-headless==4.10.0.84\" \"pandas==2.2.2\"\n",
        "\n",
        "# PyTorch CUDA 12.1 stack (you already installed, but safe to reassert)\n",
        "!pip -q install torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 -i https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Coqui TTS last (so it doesn’t downgrade NumPy)\n",
        "!pip -q install -U TTS==0.22.0\n",
        "\n",
        "# Sanity check\n",
        "import numpy as np, cv2, torch, pandas as pd\n",
        "print(\"NumPy\", np.__version__, \"| OpenCV\", cv2.__version__, \"| pandas\", pd.__version__, \"| CUDA?\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Ux8VfPRJNXm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ux8VfPRJNXm",
        "outputId": "1079b102-802e-41b9-85ee-043ec0463c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# make sure PyTorch stack is consistent on Colab CUDA 12.1\n",
        "!pip -q install torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 -i https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Reinstall TTS after the above, so it doesn't downgrade NumPy\n",
        "!pip -q install -U TTS==0.22.0\n",
        "\n",
        "import numpy as np; print(\"NumPy:\", np.__version__)\n",
        "import os; os.kill(os.getpid(), 9)  # force Colab runtime restart (this is normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Igkit0LYIwKd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Igkit0LYIwKd",
        "outputId": "26ae10eb-396f-46e6-a160-a008793943d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROOT = /content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/\")\n",
        "ROOT.mkdir(parents=True, exist_ok=True)\n",
        "print(\"ROOT =\", ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "09z27nxzHmvj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09z27nxzHmvj",
        "outputId": "aacba71c-9ec1-417b-8106-f87f5b4ff454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "audio:\n",
            "  lra: 11\n",
            "  target_lufs: -16\n",
            "  true_peak: -1.5\n",
            "io:\n",
            "  face_image: /content/face.jpg\n",
            "  out_dir: /content/outputs\n",
            "  serve: none\n",
            "segment:\n",
            "  min_overlap: 0.25\n",
            "  target_seconds: 12.0\n",
            "serve:\n",
            "  hls_time: 4\n",
            "stitch:\n",
            "  crf: 18\n",
            "  preset: medium\n",
            "tts:\n",
            "  engine: coqui\n",
            "  model_name: tts_models/en/ljspeech/tacotron2-DDC\n",
            "  sample_rate: 22050\n",
            "  voice: en_default\n",
            "video:\n",
            "  fps: 25\n",
            "  height: 720\n",
            "  pix_fmt: yuv420p\n",
            "  sar: 1\n",
            "  width: 1280\n",
            "  xfade_seconds: 0.6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3) Configuration (edit as needed)\n",
        "import yaml\n",
        "CFG = {\n",
        "    \"io\": {\n",
        "        \"face_image\": str((ROOT / \"face.jpg\").resolve()),\n",
        "        \"out_dir\": str((ROOT / \"outputs\").resolve()),\n",
        "        \"serve\": \"none\"  # \"hls\" or \"none\" (Flask not needed inside Colab)\n",
        "    },\n",
        "    \"segment\": {\n",
        "        \"target_seconds\": 12.0,\n",
        "        \"min_overlap\": 0.25\n",
        "    },\n",
        "    \"tts\": {\n",
        "        \"engine\": \"coqui\",\n",
        "        \"sample_rate\": 22050,\n",
        "        \"voice\": \"en_default\",\n",
        "        \"model_name\": \"tts_models/en/ljspeech/tacotron2-DDC\"  # change if you like\n",
        "    },\n",
        "    \"video\": {\n",
        "        \"fps\": 25,\n",
        "        \"width\": 1280,\n",
        "        \"height\": 720,\n",
        "        \"sar\": 1,\n",
        "        \"pix_fmt\": \"yuv420p\",\n",
        "        \"xfade_seconds\": 0.6\n",
        "    },\n",
        "    \"audio\": {\n",
        "        \"target_lufs\": -16,\n",
        "        \"true_peak\": -1.5,\n",
        "        \"lra\": 11\n",
        "    },\n",
        "    \"stitch\": {\n",
        "        \"crf\": 18,\n",
        "        \"preset\": \"medium\"\n",
        "    },\n",
        "    \"serve\": {\n",
        "        \"hls_time\": 4\n",
        "    }\n",
        "}\n",
        "(Path(ROOT) / \"config.yaml\").write_text(yaml.safe_dump(CFG))\n",
        "print(yaml.safe_dump(CFG))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "SOjanniZHmvm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOjanniZHmvm",
        "outputId": "1fea7f1f-a147-4423-f907-5382d10feddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Face image at: /content/face.jpg exists: True\n"
          ]
        }
      ],
      "source": [
        "# 4) Download a sample face image (or upload your own to ROOT/face.jpg)\n",
        "import urllib.request, shutil\n",
        "target = Path(CFG[\"io\"][\"face_image\"])\n",
        "if not target.exists():\n",
        "    url = \"https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=800\"  # a neutral portrait\n",
        "    with urllib.request.urlopen(url) as r, open(target, \"wb\") as f:\n",
        "        shutil.copyfileobj(r, f)\n",
        "print(\"Face image at:\", target, \"exists:\", target.exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "gCsgRN3WHmvq",
      "metadata": {
        "id": "gCsgRN3WHmvq"
      },
      "outputs": [],
      "source": [
        "# 5) Helpers: ffprobe/ffmpeg wrappers, segmentation, TTS, Wav2Lip, stitch\n",
        "import subprocess, shlex, re, json, uuid, math\n",
        "from pathlib import Path\n",
        "\n",
        "OUT = Path(CFG[\"io\"][\"out_dir\"]); OUT.mkdir(parents=True, exist_ok=True)\n",
        "TMP = (OUT / f\"tmp_{uuid.uuid4().hex[:8]}\"); TMP.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def run(cmd, check=True):\n",
        "    print(\">>\", \" \".join(cmd) if isinstance(cmd,list) else cmd)\n",
        "    return subprocess.run(cmd, check=check)\n",
        "\n",
        "def ffprobe_json(path):\n",
        "    cmd = [\"ffprobe\",\"-v\",\"error\",\"-print_format\",\"json\",\"-show_streams\",\"-show_format\",str(path)]\n",
        "    j = subprocess.check_output(cmd)\n",
        "    return json.loads(j)\n",
        "\n",
        "def dur_s(path):\n",
        "    try:\n",
        "        d = float(subprocess.check_output([\"ffprobe\",\"-v\",\"error\",\"-show_entries\",\"format=duration\",\"-of\",\"default=nk=1:nw=1\",str(path)]).decode().strip())\n",
        "        return d\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def auto_segment(text, target_seconds=12.0):\n",
        "    # Simple by words with ~160 wpm (~2.67 words/s): chunk ~ target_seconds * 2.67 words\n",
        "    words = text.strip().split()\n",
        "    chunk_size = max(12, int(target_seconds * 2.67))\n",
        "    segs = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        seg = \" \".join(words[i:i+chunk_size])\n",
        "        segs.append(seg)\n",
        "        i += chunk_size\n",
        "    return segs\n",
        "\n",
        "def tts_coqui(text_list, sr=22050, model=\"tts_models/en/ljspeech/tacotron2-DDC\"):\n",
        "    from TTS.api import TTS\n",
        "    tts = TTS(model_name=model, progress_bar=False, gpu=True)\n",
        "    wavs = []\n",
        "    for i, t in enumerate(text_list):\n",
        "        out = TMP / f\"seg_{i:03d}.wav\"\n",
        "        tts.tts_to_file(text=t, file_path=str(out), speaker=None, language=None)\n",
        "        wavs.append(out)\n",
        "    return wavs\n",
        "\n",
        "def loudnorm_batch(wavs, I=-16, LRA=11, TP=-1.5):\n",
        "    outs = []\n",
        "    for w in wavs:\n",
        "        o = TMP / (w.stem + \"_ln.wav\")\n",
        "        cmd = [\n",
        "          \"ffmpeg\",\"-y\",\"-i\",str(w),\n",
        "          \"-filter:a\", f\"loudnorm=I={I}:LRA={LRA}:TP={TP}:print_format=summary\",\n",
        "          str(o)\n",
        "        ]\n",
        "        run(cmd)\n",
        "        outs.append(o)\n",
        "    return outs\n",
        "\n",
        "def wav2lip_batch(face_img, wavs):\n",
        "    outs = []\n",
        "    w2l = Path(\"/content/Wav2Lip\")\n",
        "    weight = None\n",
        "    if (w2l/\"checkpoints/wav2lip_gan.pth\").exists(): weight = w2l/\"checkpoints/wav2lip_gan.pth\"\n",
        "    elif (w2l/\"wav2lip.pth\").exists(): weight = w2l/\"wav2lip.pth\"\n",
        "    else: raise RuntimeError(\"Wav2Lip weights not found.\")\n",
        "    for i, w in enumerate(wavs):\n",
        "        out = TMP / f\"seg_{i:03d}.mp4\"\n",
        "        cmd = [\n",
        "          \"python\", str(w2l/\"inference.py\"),\n",
        "          \"--checkpoint_path\", str(weight),\n",
        "          \"--face\", str(face_img),\n",
        "          \"--audio\", str(w),\n",
        "          \"--static\",\"True\",\n",
        "          \"--pads\", \"0\",\"10\",\"0\",\"0\",\n",
        "          \"--nosmooth\",\n",
        "          \"--outfile\", str(out)\n",
        "        ]\n",
        "        run(cmd)\n",
        "        outs.append(out)\n",
        "    return outs\n",
        "\n",
        "def validate_conform(mp4, fps=25, w=1280, h=720, sar=1, pix_fmt=\"yuv420p\"):\n",
        "    j = ffprobe_json(mp4)\n",
        "    v = [s for s in j[\"streams\"] if s[\"codec_type\"]==\"video\"][0]\n",
        "    # fps\n",
        "    r = v.get(\"r_frame_rate\",\"25/1\").split(\"/\")\n",
        "    vfps = float(r[0])/float(r[1])\n",
        "    sar_s = v.get(\"sample_aspect_ratio\",\"1:1\")\n",
        "    need = (abs(vfps-fps)>0.01) or (sar_s not in (\"1:1\", f\"{sar}:1\")) or (int(v[\"width\"])!=w) or (int(v[\"height\"])!=h) or (v.get(\"pix_fmt\")!=pix_fmt)\n",
        "    if not need:\n",
        "        return mp4\n",
        "    out = TMP / (Path(mp4).stem + \"_conf.mp4\")\n",
        "    cmd = [\n",
        "      \"ffmpeg\",\"-y\",\"-i\",str(mp4),\n",
        "      \"-vf\", f\"scale={w}:{h},setsar={sar},format={pix_fmt}\",\n",
        "      \"-r\", str(fps),\n",
        "      \"-c:v\",\"libx264\",\"-preset\",\"medium\",\"-crf\",\"18\",\n",
        "      \"-c:a\",\"aac\",\"-ar\",\"44100\",\"-ac\",\"2\",\n",
        "      \"-movflags\",\"+faststart\", str(out)\n",
        "    ]\n",
        "    run(cmd)\n",
        "    return out\n",
        "\n",
        "def xfade_stitch(mp4s, xfade_s=0.6, fps=25, crf=18, preset=\"medium\", pix_fmt=\"yuv420p\"):\n",
        "    # Build dynamic filter_complex with per-pair durations\n",
        "    n = len(mp4s)\n",
        "    if n==1:\n",
        "        final = OUT / \"final.mp4\"\n",
        "        run([\"ffmpeg\",\"-y\",\"-i\",str(mp4s[0]),\"-c\",\"copy\",str(final)])\n",
        "        return final\n",
        "\n",
        "    inputs = []\n",
        "    for p in mp4s:\n",
        "        inputs += [\"-i\", str(p)]\n",
        "    # Precompute durations\n",
        "    durs = [dur_s(p) for p in mp4s]\n",
        "\n",
        "    vf_parts = []\n",
        "    af_parts = []\n",
        "    v_labels = []\n",
        "    a_labels = []\n",
        "\n",
        "    # normalize streams per input\n",
        "    for i in range(n):\n",
        "        vf_parts.append(f\"[{i}:v]fps={fps},format={pix_fmt},scale={CFG['video']['width']}:{CFG['video']['height']},setsar={CFG['video']['sar']}[v{i}]\")\n",
        "        af_parts.append(f\"[{i}:a]aresample=async=1,aresample=44100[a{i}]\")\n",
        "        v_labels.append(f\"v{i}\")\n",
        "        a_labels.append(f\"a{i}\")\n",
        "\n",
        "    v_prev = v_labels[0]\n",
        "    a_prev = a_labels[0]\n",
        "    step = []\n",
        "    for i in range(1, n):\n",
        "        off = max(0.0, durs[i-1] - xfade_s)\n",
        "        v_out = f\"v{i}o\"\n",
        "        a_out = f\"a{i}o\"\n",
        "        step.append(f\"[{v_prev}][{v_labels[i]}]xfade=transition=fade:duration={xfade_s}:offset={off:.3f}[{v_out}]\")\n",
        "        step.append(f\"[{a_prev}][{a_labels[i]}]acrossfade=d={xfade_s}[{a_out}]\")\n",
        "        v_prev, a_prev = v_out, a_out\n",
        "\n",
        "    filter_complex = \"; \".join(vf_parts + af_parts + step)\n",
        "    final = OUT / \"final.mp4\"\n",
        "    cmd = [\"ffmpeg\",\"-y\"] + inputs + [\n",
        "        \"-filter_complex\", filter_complex,\n",
        "        \"-map\", f\"[{v_prev}]\", \"-map\", f\"[{a_prev}]\",\n",
        "        \"-c:v\",\"libx264\",\"-crf\", str(crf), \"-preset\", preset,\n",
        "        \"-pix_fmt\", pix_fmt, \"-c:a\",\"aac\",\"-movflags\",\"+faststart\",\n",
        "        str(final)\n",
        "    ]\n",
        "    run(cmd)\n",
        "    return final\n",
        "\n",
        "def export_hls(mp4, hls_time=4):\n",
        "    hls_dir = OUT / \"hls\"; hls_dir.mkdir(exist_ok=True)\n",
        "    index = hls_dir / \"index.m3u8\"\n",
        "    cmd = [\n",
        "      \"ffmpeg\",\"-y\",\"-i\",str(mp4),\n",
        "      \"-profile:v\",\"baseline\",\"-level\",\"3.0\",\n",
        "      \"-start_number\",\"0\",\"-hls_time\",str(hls_time),\"-hls_list_size\",\"0\",\n",
        "      \"-f\",\"hls\", str(index)\n",
        "    ]\n",
        "    run(cmd)\n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "mLyMKyr4Hmvy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLyMKyr4Hmvy",
        "outputId": "32d3d2aa-faff-4e9b-e539-af53872e627c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segments: 2\n",
            "01. Hello! This is a short demo for Alethea AI Track C. We split the text into segments, synthesize spee ...\n",
            "02. this text to be as long as you want; the pipeline will handle it in chunks. \n"
          ]
        }
      ],
      "source": [
        "# 6) Enter your script text\n",
        "TEXT = \"Hello! This is a short demo for Alethea AI Track C. We split the text into segments, synthesize speech, lip-sync using Wav2Lip, stitch with gentle crossfades, and export HLS. You can edit this text to be as long as you want; the pipeline will handle it in chunks.\"\n",
        "\n",
        "segs = auto_segment(TEXT, target_seconds=CFG[\"segment\"][\"target_seconds\"])\n",
        "print(\"Segments:\", len(segs))\n",
        "for i, s in enumerate(segs): print(f\"{i+1:02d}.\", s[:100], \"...\" if len(s)>100 else \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "UkxavBzANzRV",
      "metadata": {
        "id": "UkxavBzANzRV"
      },
      "outputs": [],
      "source": [
        "def wav2lip_batch(face_img, wavs):\n",
        "    import subprocess, shlex\n",
        "    from pathlib import Path\n",
        "    outs = []\n",
        "    w2l = Path(\"/content/Wav2Lip\")\n",
        "    weight = None\n",
        "    if (w2l/\"checkpoints/wav2lip_gan.pth\").exists(): weight = w2l/\"checkpoints/wav2lip_gan.pth\"\n",
        "    elif (w2l/\"wav2lip.pth\").exists():   weight = w2l/\"wav2lip.pth\"\n",
        "    else: raise RuntimeError(\"Wav2Lip weights not found.\")\n",
        "\n",
        "    # # sanity: face & s3fd\n",
        "    # s3fd = w2l / \"face_detection/detection/sfd/s3fd.pth\"\n",
        "    # assert Path(face_img).exists(), f\"Face image missing: {face_img}\"\n",
        "    # assert s3fd.exists(), \"s3fd.pth missing; download it to face_detection/detection/sfd/\"\n",
        "\n",
        "    for i, w in enumerate(wavs):\n",
        "        out = TMP / f\"seg_{i:03d}.mp4\"\n",
        "        cmd = [\n",
        "          \"python\", str(w2l/\"inference.py\"),\n",
        "          \"--checkpoint_path\", str(weight),\n",
        "          \"--face\", str(face_img),\n",
        "          \"--audio\", str(w),\n",
        "          \"--static\",\"True\",                 # <-- REQUIRED for single image\n",
        "          \"--pads\", \"0\",\"10\",\"0\",\"0\",\n",
        "          \"--resize_factor\", \"2\",     # faster on CPU, ok on GPU too\n",
        "          \"--nosmooth\",\n",
        "          \"--outfile\", str(out)\n",
        "        ]\n",
        "        print(\">>\", \" \".join(cmd))\n",
        "        p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        print(p.stdout)               # show Wav2Lip’s own error messages\n",
        "        if p.returncode != 0:\n",
        "            raise RuntimeError(f\"Wav2Lip failed on {w.name} (see logs above)\")\n",
        "        outs.append(out)\n",
        "    return outs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "NlRCimRfHmv3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlRCimRfHmv3",
        "outputId": "7193812d-ce41-41e3-f30d-baffb8c2971b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/TTS/api.py:70: UserWarning: `gpu` will be deprecated. Please use `tts.to(device)` instead.\n",
            "  warnings.warn(\"`gpu` will be deprecated. Please use `tts.to(device)` instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
            " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
            " > Using model: Tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Model's reduction rate `r` is set to: 1\n",
            " > Vocoder Model: hifigan\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:False\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:8000.0\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:2.718281828459045\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Generator Model: hifigan_generator\n",
            " > Discriminator Model: hifigan_discriminator\n",
            "Removing weight norm...\n",
            " > Text splitted to sentences.\n",
            "['Hello!', 'This is a short demo for Alethea AI Track C. We split the text into segments, synthesize speech, lip-sync using Wav2Lip, stitch with gentle crossfades, and export HLS.', 'You can edit']\n",
            " > Processing time: 1.604719638824463\n",
            " > Real-time factor: 0.09414261854561164\n",
            " > Text splitted to sentences.\n",
            "['this text to be as long as you want; the pipeline will handle it in chunks.']\n",
            " > Processing time: 0.536287784576416\n",
            " > Real-time factor: 0.0921880507820099\n",
            "TTS wavs: [PosixPath('/content/outputs/tmp_05304231/seg_000.wav'), PosixPath('/content/outputs/tmp_05304231/seg_001.wav')]\n",
            ">> ffmpeg -y -i /content/outputs/tmp_05304231/seg_000.wav -filter:a loudnorm=I=-16:LRA=11:TP=-1.5:print_format=summary /content/outputs/tmp_05304231/seg_000_ln.wav\n",
            ">> ffmpeg -y -i /content/outputs/tmp_05304231/seg_001.wav -filter:a loudnorm=I=-16:LRA=11:TP=-1.5:print_format=summary /content/outputs/tmp_05304231/seg_001_ln.wav\n",
            "Loudnorm wavs: [PosixPath('/content/outputs/tmp_05304231/seg_000_ln.wav'), PosixPath('/content/outputs/tmp_05304231/seg_001_ln.wav')]\n",
            ">> python /content/Wav2Lip/inference.py --checkpoint_path /content/Wav2Lip/checkpoints/wav2lip_gan.pth --face /content/face.jpg --audio /content/outputs/tmp_05304231/seg_000_ln.wav --static True --pads 0 10 0 0 --resize_factor 2 --nosmooth --outfile /content/outputs/tmp_05304231/seg_000.mp4\n",
            "Using cuda for inference.\n",
            "Number of frames available for inference: 1\n",
            "(80, 1364)\n",
            "Length of mel chunks: 423\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\u001b[A\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
            "\n",
            " 25%|██▌       | 1/4 [00:15<00:45, 15.15s/it]\n",
            " 50%|█████     | 2/4 [00:16<00:14,  7.13s/it]\n",
            " 75%|███████▌  | 3/4 [00:17<00:04,  4.36s/it]\n",
            "100%|██████████| 4/4 [00:21<00:00,  4.27s/it]\n",
            "100%|██████████| 4/4 [00:21<00:00,  5.47s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, wav, from '/content/outputs/tmp_05304231/seg_000_ln.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:17.05, bitrate: 3072 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 192000 Hz, mono, s16, 3072 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:16.92, start: 0.000000, bitrate: 861 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 800x1200 [SAR 1:1 DAR 2:3], 855 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x5789b64ee680] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x5789b64ee680] using SAR=1/1\n",
            "[libx264 @ 0x5789b64ee680] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x5789b64ee680] profile High, level 3.2, 4:2:0, 8-bit\n",
            "[libx264 @ 0x5789b64ee680] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/outputs/tmp_05304231/seg_000.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 800x1200 [SAR 1:1 DAR 2:3], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=   57 fps=0.0 q=28.0 size=       0kB time=00:00:00.28 bitrate=   1.4kbits/s speed=0.463x    \n",
            "frame=   79 fps= 70 q=28.0 size=       0kB time=00:00:01.16 bitrate=   0.3kbits/s speed=1.02x    \n",
            "frame=  101 fps= 62 q=28.0 size=       0kB time=00:00:02.04 bitrate=   0.2kbits/s speed=1.25x    \n",
            "frame=  127 fps= 59 q=28.0 size=       0kB time=00:00:03.08 bitrate=   0.1kbits/s speed=1.43x    \n",
            "frame=  153 fps= 57 q=28.0 size=       0kB time=00:00:04.12 bitrate=   0.1kbits/s speed=1.53x    \n",
            "frame=  180 fps= 56 q=28.0 size=       0kB time=00:00:05.20 bitrate=   0.1kbits/s speed=1.62x    \n",
            "frame=  204 fps= 55 q=28.0 size=       0kB time=00:00:06.16 bitrate=   0.1kbits/s speed=1.66x    \n",
            "frame=  229 fps= 54 q=28.0 size=     256kB time=00:00:07.16 bitrate= 292.9kbits/s speed= 1.7x    \n",
            "frame=  252 fps= 53 q=28.0 size=     256kB time=00:00:08.08 bitrate= 259.6kbits/s speed=1.71x    \n",
            "frame=  272 fps= 52 q=28.0 size=     256kB time=00:00:08.88 bitrate= 236.2kbits/s speed=1.69x    \n",
            "frame=  288 fps= 50 q=28.0 size=     256kB time=00:00:09.52 bitrate= 220.3kbits/s speed=1.66x    \n",
            "frame=  301 fps= 48 q=28.0 size=     256kB time=00:00:10.04 bitrate= 208.9kbits/s speed= 1.6x    \n",
            "frame=  319 fps= 47 q=28.0 size=     256kB time=00:00:10.76 bitrate= 194.9kbits/s speed=1.58x    \n",
            "frame=  337 fps= 46 q=28.0 size=     256kB time=00:00:11.48 bitrate= 182.7kbits/s speed=1.56x    \n",
            "frame=  354 fps= 45 q=28.0 size=     256kB time=00:00:12.16 bitrate= 172.5kbits/s speed=1.54x    \n",
            "frame=  370 fps= 44 q=28.0 size=     256kB time=00:00:12.80 bitrate= 163.9kbits/s speed=1.53x    \n",
            "frame=  397 fps= 45 q=28.0 size=     512kB time=00:00:13.88 bitrate= 302.2kbits/s speed=1.56x    \n",
            "frame=  423 fps= 45 q=28.0 size=     512kB time=00:00:16.60 bitrate= 252.6kbits/s speed=1.76x    \n",
            "frame=  423 fps= 42 q=-1.0 Lsize=     625kB time=00:00:17.04 bitrate= 300.2kbits/s speed=1.69x    \n",
            "video:470kB audio:136kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.030947%\n",
            "[libx264 @ 0x5789b64ee680] frame I:2     Avg QP:14.84  size: 38609\n",
            "[libx264 @ 0x5789b64ee680] frame P:117   Avg QP:16.62  size:  2111\n",
            "[libx264 @ 0x5789b64ee680] frame B:304   Avg QP:19.85  size:   514\n",
            "[libx264 @ 0x5789b64ee680] consecutive B-frames:  1.4%  7.6%  2.1% 88.9%\n",
            "[libx264 @ 0x5789b64ee680] mb I  I16..4: 17.2% 75.7%  7.1%\n",
            "[libx264 @ 0x5789b64ee680] mb P  I16..4:  0.1%  1.4%  0.0%  P16..4:  8.6%  2.1%  1.2%  0.0%  0.0%    skip:86.6%\n",
            "[libx264 @ 0x5789b64ee680] mb B  I16..4:  0.0%  0.3%  0.0%  B16..8:  7.3%  0.2%  0.0%  direct: 0.0%  skip:92.0%  L0:54.3% L1:44.6% BI: 1.1%\n",
            "[libx264 @ 0x5789b64ee680] 8x8 transform intra:84.6% inter:96.5%\n",
            "[libx264 @ 0x5789b64ee680] coded y,uvDC,uvAC intra: 62.3% 42.4% 7.6% inter: 1.1% 1.4% 0.0%\n",
            "[libx264 @ 0x5789b64ee680] i16 v,h,dc,p: 36% 27% 21% 17%\n",
            "[libx264 @ 0x5789b64ee680] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 22% 37%  2%  3%  3%  3%  3%  3%\n",
            "[libx264 @ 0x5789b64ee680] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 45% 28%  9%  2%  4%  5%  4%  2%  1%\n",
            "[libx264 @ 0x5789b64ee680] i8c dc,h,v,p: 52% 21% 21%  6%\n",
            "[libx264 @ 0x5789b64ee680] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x5789b64ee680] ref P L0: 60.1%  8.3% 19.9% 11.6%\n",
            "[libx264 @ 0x5789b64ee680] ref B L0: 69.6% 25.5%  4.8%\n",
            "[libx264 @ 0x5789b64ee680] ref B L1: 95.1%  4.9%\n",
            "[libx264 @ 0x5789b64ee680] kb/s:227.17\n",
            "[aac @ 0x5789b64ef940] Qavg: 5259.183\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            ">> python /content/Wav2Lip/inference.py --checkpoint_path /content/Wav2Lip/checkpoints/wav2lip_gan.pth --face /content/face.jpg --audio /content/outputs/tmp_05304231/seg_001_ln.wav --static True --pads 0 10 0 0 --resize_factor 2 --nosmooth --outfile /content/outputs/tmp_05304231/seg_001.mp4\n",
            "Using cuda for inference.\n",
            "Number of frames available for inference: 1\n",
            "(80, 466)\n",
            "Length of mel chunks: 142\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\u001b[A\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
            "\n",
            " 50%|█████     | 1/2 [00:13<00:13, 13.86s/it]\n",
            "100%|██████████| 2/2 [00:16<00:00,  7.04s/it]\n",
            "100%|██████████| 2/2 [00:16<00:00,  8.07s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, wav, from '/content/outputs/tmp_05304231/seg_001_ln.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:05.82, bitrate: 3072 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 192000 Hz, mono, s16, 3072 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:05.68, start: 0.000000, bitrate: 864 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 800x1200 [SAR 1:1 DAR 2:3], 857 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x5b337c87c200] -qscale is ignored, -crf is recommended.\n",
            "[libx264 @ 0x5b337c87c200] using SAR=1/1\n",
            "[libx264 @ 0x5b337c87c200] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "[libx264 @ 0x5b337c87c200] profile High, level 3.2, 4:2:0, 8-bit\n",
            "[libx264 @ 0x5b337c87c200] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/outputs/tmp_05304231/seg_001.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 800x1200 [SAR 1:1 DAR 2:3], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 96000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    1 fps=0.0 q=0.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
            "frame=   59 fps=0.0 q=28.0 size=       0kB time=00:00:00.36 bitrate=   1.1kbits/s speed=0.678x    \n",
            "frame=   73 fps= 68 q=28.0 size=       0kB time=00:00:00.92 bitrate=   0.4kbits/s speed=0.853x    \n",
            "frame=   90 fps= 57 q=28.0 size=       0kB time=00:00:01.60 bitrate=   0.2kbits/s speed=1.01x    \n",
            "frame=  107 fps= 50 q=28.0 size=       0kB time=00:00:02.28 bitrate=   0.2kbits/s speed=1.08x    \n",
            "frame=  126 fps= 48 q=28.0 size=       0kB time=00:00:03.04 bitrate=   0.1kbits/s speed=1.15x    \n",
            "frame=  142 fps= 45 q=28.0 size=       0kB time=00:00:03.95 bitrate=   0.1kbits/s speed=1.26x    \n",
            "frame=  142 fps= 34 q=-1.0 Lsize=     228kB time=00:00:05.81 bitrate= 321.7kbits/s speed=1.39x    \n",
            "video:175kB audio:46kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 3.224567%\n",
            "[libx264 @ 0x5b337c87c200] frame I:1     Avg QP:16.71  size: 29170\n",
            "[libx264 @ 0x5b337c87c200] frame P:38    Avg QP:16.55  size:  2454\n",
            "[libx264 @ 0x5b337c87c200] frame B:103   Avg QP:19.95  size:   544\n",
            "[libx264 @ 0x5b337c87c200] consecutive B-frames:  1.4%  5.6%  0.0% 93.0%\n",
            "[libx264 @ 0x5b337c87c200] mb I  I16..4: 22.7% 76.0%  1.3%\n",
            "[libx264 @ 0x5b337c87c200] mb P  I16..4:  0.1%  1.4%  0.0%  P16..4:  9.5%  2.5%  1.5%  0.0%  0.0%    skip:85.1%\n",
            "[libx264 @ 0x5b337c87c200] mb B  I16..4:  0.1%  0.5%  0.0%  B16..8:  7.0%  0.2%  0.0%  direct: 0.0%  skip:92.1%  L0:49.6% L1:49.1% BI: 1.3%\n",
            "[libx264 @ 0x5b337c87c200] 8x8 transform intra:83.3% inter:94.1%\n",
            "[libx264 @ 0x5b337c87c200] coded y,uvDC,uvAC intra: 58.4% 39.9% 5.3% inter: 1.3% 1.4% 0.0%\n",
            "[libx264 @ 0x5b337c87c200] i16 v,h,dc,p: 40% 30% 16% 14%\n",
            "[libx264 @ 0x5b337c87c200] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 25% 21% 38%  3%  3%  3%  3%  2%  3%\n",
            "[libx264 @ 0x5b337c87c200] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 39% 29% 13%  2%  5%  6%  3%  2%  1%\n",
            "[libx264 @ 0x5b337c87c200] i8c dc,h,v,p: 52% 22% 21%  5%\n",
            "[libx264 @ 0x5b337c87c200] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x5b337c87c200] ref P L0: 64.0%  6.7% 19.3%  9.9%\n",
            "[libx264 @ 0x5b337c87c200] ref B L0: 67.4% 27.8%  4.7%\n",
            "[libx264 @ 0x5b337c87c200] ref B L1: 92.8%  7.2%\n",
            "[libx264 @ 0x5b337c87c200] kb/s:251.42\n",
            "[aac @ 0x5b337c87e280] Qavg: 5252.744\n",
            "Load checkpoint from: /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
            "Model loaded\n",
            "\n",
            "Wav2Lip segments: ['/content/outputs/tmp_05304231/seg_000.mp4', '/content/outputs/tmp_05304231/seg_001.mp4']\n"
          ]
        }
      ],
      "source": [
        "#7) Run TTS → Loudness → Wav2Lip per segment\n",
        "wavs = tts_coqui(segs, sr=CFG[\"tts\"][\"sample_rate\"], model=CFG[\"tts\"][\"model_name\"])\n",
        "print(\"TTS wavs:\", wavs)\n",
        "\n",
        "wavs_ln = loudnorm_batch(wavs, I=CFG[\"audio\"][\"target_lufs\"], LRA=CFG[\"audio\"][\"lra\"], TP=CFG[\"audio\"][\"true_peak\"])\n",
        "print(\"Loudnorm wavs:\", wavs_ln)\n",
        "\n",
        "\n",
        "mp4s = wav2lip_batch(CFG[\"io\"][\"face_image\"], wavs_ln)\n",
        "print(\"Wav2Lip segments:\", [str(p) for p in mp4s])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3b75DqTlUUPR",
      "metadata": {
        "id": "3b75DqTlUUPR"
      },
      "outputs": [],
      "source": [
        "import os, pathlib\n",
        "os.makedirs(\"/content/temp\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "BU9IA-cDHmv8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU9IA-cDHmv8",
        "outputId": "9ad2c4d2-2973-46a9-c8d8-77e14b4592bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> ffmpeg -y -i /content/outputs/tmp_05304231/seg_000.mp4 -vf scale=1280:720,setsar=1,format=yuv420p -r 25 -c:v libx264 -preset medium -crf 18 -c:a aac -ar 44100 -ac 2 -movflags +faststart /content/outputs/tmp_05304231/seg_000_conf.mp4\n",
            ">> ffmpeg -y -i /content/outputs/tmp_05304231/seg_001.mp4 -vf scale=1280:720,setsar=1,format=yuv420p -r 25 -c:v libx264 -preset medium -crf 18 -c:a aac -ar 44100 -ac 2 -movflags +faststart /content/outputs/tmp_05304231/seg_001_conf.mp4\n",
            ">> ffmpeg -y -i /content/outputs/tmp_05304231/seg_000_conf.mp4 -i /content/outputs/tmp_05304231/seg_001_conf.mp4 -filter_complex [0:v]fps=25,format=yuv420p,scale=1280:720,setsar=1[v0]; [1:v]fps=25,format=yuv420p,scale=1280:720,setsar=1[v1]; [0:a]aresample=async=1,aresample=44100[a0]; [1:a]aresample=async=1,aresample=44100[a1]; [v0][v1]xfade=transition=fade:duration=0.6:offset=16.457[v1o]; [a0][a1]acrossfade=d=0.6[a1o] -map [v1o] -map [a1o] -c:v libx264 -crf 18 -preset medium -pix_fmt yuv420p -c:a aac -movflags +faststart /content/outputs/final.mp4\n",
            "Final MP4: /content/outputs/final.mp4\n"
          ]
        }
      ],
      "source": [
        "valid = [validate_conform(m,\n",
        "                          fps=CFG[\"video\"][\"fps\"],\n",
        "                          w=CFG[\"video\"][\"width\"],\n",
        "                          h=CFG[\"video\"][\"height\"],\n",
        "                          sar=CFG[\"video\"][\"sar\"],\n",
        "                          pix_fmt=CFG[\"video\"][\"pix_fmt\"]) for m in mp4s]\n",
        "\n",
        "final_mp4 = xfade_stitch(valid,\n",
        "                         xfade_s=CFG[\"video\"][\"xfade_seconds\"],\n",
        "                         fps=CFG[\"video\"][\"fps\"],\n",
        "                         crf=CFG[\"stitch\"][\"crf\"],\n",
        "                         preset=CFG[\"stitch\"][\"preset\"],\n",
        "                         pix_fmt=CFG[\"video\"][\"pix_fmt\"])\n",
        "print(\"Final MP4:\", final_mp4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "_kil0mrpHmv_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "resources": {
            "http://localhost:8080/content/outputs/final.mp4": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "_kil0mrpHmv_",
        "outputId": "ffc204b0-b13d-4f37-e962-a4481c7e5965"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<video src=\"/content/outputs/final.mp4\" controls playsinline style=\"max-width:100%;height:auto\"></video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#9) Preview in Colab\n",
        "from IPython.display import HTML\n",
        "html = f'''\n",
        "<video src=\"{final_mp4}\" controls playsinline style=\"max-width:100%;height:auto\"></video>\n",
        "'''\n",
        "HTML(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f8f02c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable HLS export\n",
        "CFG.setdefault(\"io\", {})\n",
        "CFG.setdefault(\"serve\", {})\n",
        "CFG[\"io\"][\"serve\"] = \"hls\"          \n",
        "CFG[\"serve\"][\"hls_time\"] = 4        # 4–6s is typical segment size\n",
        "\n",
        "# Re-run step 10\n",
        "if CFG[\"io\"][\"serve\"] == \"hls\":\n",
        "    assert 'final_mp4' in globals(), \"final_mp4 not found — run the stitch step first.\"\n",
        "    m3u8 = export_hls(final_mp4, hls_time=CFG[\"serve\"][\"hls_time\"])\n",
        "else:\n",
        "    print(\"CFG['io']['serve'] is 'none'; skipping HLS. Set it to 'hls' to export.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73E3rGEwHmwB",
      "metadata": {
        "id": "73E3rGEwHmwB"
      },
      "source": [
        "### Notes & Tips\n",
        "\n",
        "- **Black screen prevention:** we always re-encode during crossfades and force `format=yuv420p`, constant FPS, and `setsar=1` inside the filtergraph.\n",
        "- **Change model/voice:** update `CFG[\"tts\"][\"model_name\"]`; Coqui provides many multilingual voices.\n",
        "- **Long scripts:** the simple word-based segmenter targets ~12s chunks. Adjust `target_seconds` or replace with a punctuation-aware splitter.\n",
        "- **Weights:** If `gdown` fails to fetch `wav2lip_gan.pth`, try re-running cell 1 or upload weights to `ROOT` and move them into `/content/Wav2Lip`.\n",
        "- **Speed-ups:** lower resolution (e.g., 720p) and keep FPS at 25. Consider batching TTS and running Wav2Lip sequentially on a single GPU."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
